* Linux性能优化 - 如何学习
1. 理解应用程序和系统的少数几个基本原理, 再进行大量的实战练习, 建立起整体性能的全局观.
2. 性能问题的本质就是系统资源已经达到了瓶颈, 但请求的处理却还不够快, 无法支撑更多的请求
3. 性能分析就是找出应用或系统的瓶颈, 并设法去避免或缓解它们, 从而高效的利用系统资源处理更多的请求
   包含下面6个步骤:
   1. 选择指标评估应用程序和系统的性能
   2. 为应用程序和系统设置性能目标
   3. 进行性能基准测试
   4. 性能分析定位瓶颈
   5. 优化系统和应用程序
   6. 性能监控和告警
[[file:~/Learn_space/blog_notes/OS/img/linux_perf_tools_full.png][Linux性能图谱]]
该图是linux性能分析最重要的参考资料之一, 在Linux不同子系统出现性能问题后, 应该用什么样的工具来观测
和分析.

** 学习技巧
1. 虽然系统的原理很重要, 但在刚开始一定不要试图抓住所有的实现细节
2. 边学边实践, 通过大量的案例演习掌握linux性能的分析和优化
3. 勤思考、多反思、善总结、多问为什么

* 平均负载
** 命令介绍
top
uptime

** 平均负载
平均负载指单位时间内, 系统处于可运行状态和不可中断状态的平均进程数, 即平均活跃进程数. 实际上是
活跃进程数的指数衰减平均值, 与CPU的使用率没有直接关系.

可运行状态: 正在使用CPU或者正在等待CPU的进程, 即ps命令看到的处于R(running或runnable)的进程
不可中断状态: 正处于内核关键流程中的进程, 并且这些流程是不可打断的, 如: 等待硬件设备的I/O响应,
ps命令中看到的D状态(uninterruptible sleep, 也称为Disk Sleep)

当一个进程向磁盘读写数据时, 为了保证数据的一致性, 得到磁盘回复前, 是不能被其他进程或中断打断的.

不可中断状态实际上是系统对进程和硬件设备的一种保护机制.

** 平均负载为多少时合理
平均负载最理想的情况等于cpu个数, 在评判平均负载时, 首先要知道系统有几个CPU(逻辑cpu).
可以通过top命令 或/proc/cpuinfo文件中读取
grep 'model name' /proc/cpuinfo | wc -l

假设在单个CPU系统上看到了平均负载为1.73, 0.60, 7.98, 即表示过去1min内系统有73%的超载, 15分钟内
有698%的超载, 从整体趋势来看, 系统的负载在降低.

一般情况下, 当平均负载高于CPU数量的70%时, 就应该分析排查负载高的问题了.

** 平均负载与CPU使用率
CPU使用率是单位时间内cpu最繁忙情况的统计, 跟平均负载并不一定完全对应.
如:
CPU密集型进程, 使用大量的CPU会导致平均负载升高, 此时两者一致
I/O密集型, 等待I/O会导致平均负载升高, 但CPU使用率不一定很高
大量等待CPU的进程调度也会导致平均负载升高, 此时的CPU使用率也会比较高.

** 平均负载案例分析
1. 准备工作
   预先安装stree, sysstat包

   stree是一个linux系统压力测试工具
   sysstat包含了常用的linux性能工具, 用来监控和分析系统的性能. 其中的mpstat是一个常用的多核CPU
   性能分析工具, 用来事实查看每个CPU的性能指标, 以及所有CPU的平均指标
   
   pidstat: 进程性能分析工具, 用来实时查看进程的CPU、内存、I/O以及上下文切换等性能指标

2. 场景1: CPU密集型进程
   在一个终端运行stress命令, 模拟一个cpu使用率100%的场景
   stress --cpu 1 --timeout 600
   第二个终端中运行uptime查看平均负载的变化情况:
   watch -d uptime  # -d 参数表示高亮显示变化的区域
   在第3个终端运行mpstat查看cpu使用率的变化情况:
   mpstat -P ALL 5  # -P ALL表示监控所有CPU, 后面数字5表示间隔5s后输出一组数据

   pidstat -u 5 1  # 间隔5s后输出一组数据, 查看哪个进程导致了cpu使用率

3. 场景2: I/O密集型进程
   stress -i 1 --timeout 600  # 模拟I/O压力
   watch -d uptime  # 监控uptime的负载变化
   mpstat -P ALL 5  # 查看所有的CPU使用情况
   pidstat -u 5  # 查看耗时的进程

4. 场景3: 大量进程
   stress -c 8 --timeout 600
   pidstat -u 5
* CPU上下文切换
** 介绍
进程在竞争CPU时, 为什么会导致系统的负载升高呢? 原因是CPU上下文切换.

Linux是一个多任务OS, 支持任务同时运行, 但这些任务实际上并不是真的同时运行, 而是因为系统在很短的
时间内将CPU轮流分配给它们, 造成多任务同时运行的错觉.

而在每个任务运行前, CPU都需要知道任务从哪里加载、从哪里开始运行, 即需要系统事先设置好CPU寄存器和
程序计数器. 它们都是CPU在运行任何任务前, 必须的依赖环境, 因此也叫做CPU上下文.

CPU上下文切换, 就是先把前一个任务的CPU上下文(即CPU寄存器和程序计数器)保存起来, 然后加载新任务的
上下文到这些寄存器和程序计数器, 然后再跳转到程序计数器所指的新位置, 运行新任务.

这些被保存下来的上下文, 会存储在系统内核中, 并在任务重新调度执行时再次加载进来. 这样就能保证任务
原来的状态不受影响, 让任务看起来还是连续运行的.

根据任务的不同, CPU的上下文切换可以分为几个不同的场景: 进程上下文切换、线程上下文切换、中断
上下文切换.

** 进程上下文切换
从用户态到内核态的转变, 需要通过系统调用来完成. 一次系统调用的过程, 发生了两次CPU上下文切换.
系统调用过程中, 不会涉及到虚拟内存等进程用户态的资源, 也不会切换进程, 这跟通常说的进程上下文
切换是不一样的:
进程上下文切换是指从一个进程切换到另一个进程, 系统调用过程中一直是同一个进程在运行.

系统调用过程通常称为特权模式切换.

进程是由内核来管理和调度的, 进程的切换只能发生在内核态. 因此进程的上下文不仅包括了虚拟内存、栈、
全局变量等用户空间的资源, 还包括了内核堆栈、寄存器等内核空间的状态.

根据Tsuna的测试报告, 每次上下文切换都需要几十纳秒到数微妙的CPU时间, 在进程上下文切换次数较多的
情况下, 很容易导致CPU将大量时间耗费在寄存器、内核栈以及虚拟内存等资源的保存和恢复上, 从而缩短了
真正运行进程的时间.

Linux同TLB(TranslationLookaside Buffer)来管理虚拟内存到物理内存的映射关系. 当虚拟内存更新后, TLB
也需要更新, 内存的访问也会变慢. 多处理系统上, 缓存是被多个处理器共享的.

进程切换的条件:
1. 某个进程的时间片耗尽了
2. 进程在系统资源不足时
3. 进程通过sleep等函数主动挂起
4. 有优先级更高的进程需要运行
5. 发生硬件中断

** 线程上下文切换
线程是调度的基本单位, 进程则是资源拥有的基本单位.
对于线程和进程, 可以这么理解:
1. 当进程只有一个线程时, 可以认为进程等于线程
2. 当拥有多个线程时, 这些线程会共享相同的虚拟内存和全局变量资源, 这些资源在上下文切换时不需要
   修改
3. 线程也有自己私有的数据, 在上下文切换时也是需要保存的

线程上下文切换可以分为两种情况:
1. 前后两个线程属于不同进程, 等价于进程上下文切换
2. 属于同一个进程, 此时只需要切换线程的私有数据、寄存器等不共享的数据.

** 中断上下文切换
中断处理会打断进程的正常调度和执行, 转而调用中断处理程序, 响应设备事件.
中断上下文切换并不涉及到进程的用户态, 即便中断过程打断了一个正处在用户态的进程, 也不需要保存和
恢复这个进程的虚拟内存、全局变量等用户态资源.

中断上下文其实只包括内核态中断服务程序执行所必需的状态, 包括CPU寄存器、内核堆栈、硬件中断参数等

对同一个CPU来说, 中断处理比进程拥有更高的优先级. 中断上下文切换并不会与进程上下文切换同时发生.

** 查看系统上下文切换
vmstat工具: 主要用来分析系统的内存使用情况, 和cpu上下文切换和中断次数
使用示例: vmstat 5  # 每隔5s输出一组数据

vmstat重要列说明:
cs(context switch): 每秒上下文切换的次数
in(interrupt): 每秒中断的次数
r(running or runnable): 就绪队列的长度, 即正在运行和等待cpu的进程数
b(blocked): 处于不可中断睡眠状态的进程数

pidstat -w 5  # 每5s输出数据, -w选项可以查看每个进程的详细情况
该命令的输出列解释:
cswch  # 每秒自愿上下文切换(voluntary context switches)的次数
nvcswch  # 每秒非自愿上下文切换的次数(non voluntary context switches)

自愿上下文切换指进程无法获取所需资源, 导致的上下文切换. 如I/O, 内存等系统资源不足
非自愿上下文切换: 指由于时间片已到, 被系统强制调度, 进而发生的上下文切换

** 案例分析
sysbench是一个多线程的基准测试工具, 一般用来评估不同系统参数下的数据库负载情况.
安装: apt install sysbench sysstat

在一个终端中运行sysbench, 模拟多线程调度:
sysbench --threads=10 --max-time=300 threads run

系统分析: 使用vmstat 1 查看每秒系统的状态, 可以发现cs列数据陡然变大, r列的就绪队列长度已经到了
8, 远远超过系统cpu的个数, 所以会有大量的cpu竞争. us(user)+sy(system), 这两列的cpu使用率加起来
到了100%, 其中sy的使用率很高, 说明cpu主要是被内核占用了.

in列: 中断次数也上升了, 说明中断处理也是个潜在的问题.

通过以上指标可以知道, 系统的就绪队列过长, 导致了大量的上下文切换, 上下文切换导致了系统cpu的
占用率升高.

使用pidstat -w -u 1来查看cpu和进程的上下文切换状况, 可以发现cpu使用率的升高是sysbench导致的,
当上下文切换是来自其他进程, 包括非自愿上下文切换频率最高的pidstat, 以及自愿上下文切换频率最高
的内核线程kworker和sshd.

但是该pidstat命令输出的上下文切换次数加起来也就几百, 比vmstat的几百w小多了. 这是什么原因呢?
原因如下: Linux调度的基本单位实际上是线程, sysbench模拟的也是线程的调度问题. pidstat默认显示的
是进程的指标数据, 加上-t之后, 才会输出线程的指标.

vmstat的输出中中断的次数也很大, 还需要分析中断次数变大的原因. 可以从文件/proc/interrupts这个只读
文件中读取信息.

watch -d cat /proc/interrupts, 观察一段时间, 发现速度变化最快的是重调度中断(RES).
该中断表示唤醒空闲状态的CPU来调度新的任务运行, 这是多处理器系统(SMP)中, 调度器用来分散任务到不同
cpu的机制, 通常也被称为处理器间中断(inter-processor interrupts, IPI).

每秒上下文切换多少次才算正常呢?
该数值取决于系统本身的CPU性能, 如果系统上下文切换次数比较稳定, 从数百到一万以内都算是正常的.
但当上下文切换次数超过一万, 或者切换次数出现数量级的增长时, 就很可能出现了性能问题.

此时需要根据上下文切换的类型再做具体分析, 如:
1. 自愿上下文切换变多了, 说明进程都在等待资源, 有可能发生了I/O等其他问题
2. 非自愿上下文切换变多了, 说明进程在被强制调度, 即争抢CPU, 说明CPU的确成了瓶颈
3. 中断次数变多了, 说明CPU被终端处理程序占用, 还需要通过查看/proc/interrupts文件来分析具体的
   中断类型

* CPU使用率
** cpu使用率
cpu使用率是单位时间内cpu使用情况的统计, 以百分比的方式展示.

为了维护cpu时间, linux通过实现定义的节拍率(内核中表示为HZ), 触发时间中断, 并使用全局变量Jiffies
记录开机以来的节拍数. 每发生一次时间中断, Jiffies的值就加1.

节拍率是内核的可配选项, 可以设置为100、250、1000等. 不同系统可能设置不同数值, 可以通过查询
/boot/config内核选项来查看它的配置值.

grep "CONFIG_HZ=" /boot/config-$(uname -r)

用户空间不能直接访问节拍率, 内核还提供了一个用户空间节拍率USER_HZ. 总是固定为100, 即1/100秒.

Linux通过/proc虚拟文件系统, 向用户空间提供了系统内部状态信息.
/proc/stat是系统的cpu和任务统计信息, 例如: cat /proc/stat | grep ^cpu

可以通过man proc查看每一列的含义.

user(缩写为us), 代表用户态CPU时间. 注意: 不包括nice时间, 但包括了guest时间.
nice(ni), 代表低优先级用户态cpu时间, 即进程的nice值被调整为1-19之间的cpu时间, nice可取值范围是
-20到19, 数值越大优先级越低.
system(sys), 代表内核cpu时间.
idle(id), 代表空闲时间, 不包括等待I/O的时间(iowait)
iowait(wa), 代表等待I/O的cpu时间
irq(hi), 代表处理硬中断的cpu时间
softirq(si), 代表处理软中断的cpu时间
steal(st), 代表当系统运行在虚拟机中的时候, 被其他虚拟机占用的cpu时间
guest(guest), 代表通过虚拟化运行其他操作系统的时间, 即运行虚拟机的cpu时间
guset_nice(gnice), 代表以低优先运行虚拟机的时间

通常说的cpu使用率, 就是除了空闲时间外的其他时间占总cpu时间的百分比. 公式表示为:
cpu使用率 = 1 - (空闲时间) / 总cpu时间

/proc/stat中记录是开机以来的节拍数累加值, 为了计算cpu使用率, 性能工具一般都会取间隔一段时间(
如3秒)的两次值, 作差后再计算出这段时间内的平均cpu使用率, 即:
平均cpu使用率 = 1 - (空闲时间new - 空闲时间old) / (总cpu时间new - 总cpu时间old)

进程的信息可以通过/proc/[pid]/stat来查看.

性能分析工具给出的都是间隔一段时间的平均cpu使用率, 所以要注意间隔时间的设置. 特别是用多个工具
对比分析时, 一定要保证它们用的是相同的间隔时间.

top默认显示的所有cpu的平均值, 此时按下1, 可以切换到每个cpu的使用率.
top中每个进程的%CPU列, 表示进程的cpu使用率, 是用户态和内核态cpu使用率的总和, 包括进程用户空间
使用的cpu、通过系统调用执行的内核空间cpu、以及在就绪队列等待运行的cpu. 在虚拟化环境中, 还包括了
运行虚拟机占用的cpu.

pidstat命令专门分析每个进程cpu使用情况.

** cpu使用率过高
perf是Linux2.6.31以后内置的性能分析工具, 以性能时间采样为基础, 不仅可以分析系统的各种事件和内核
性能, 还可以用来分析指定应用程序的性能问题.

常见用法
1. pref top
   能够实时显示占用cpu时钟最多的函数或指令, 因此可以用来查找热点函数.
   输出结果中, 第一行包含3个数据, 分别是采样数(samples), 事件类型(event)和事件总数量(event count)
   采样数需要注意, 如果过少, 则下面的排序和百分比就没什么价值.
   
   Overhead列: 该符号的性能事件在所有采样中的比例
   Shared列: 该函数或指令所在的动态共享对象(Dynamic shared object), 如内核、进程名、动态链接库、
   内核模块名等
   Object列: 动态共享对象的类型, 如[.]表示用户空间的可执行程序、动态链接库、[k]表示内核空间
   Symbol列: 符号名, 即函数名, 当函数名未知时, 用16进制的地址来表示.

   加上-g参数, 开启调用关系的采样
2. perf record, pref report
   record提供了保存数据的功能, 保存后的数据需要使用report解析展示
   也可以加上-g参数.
* 工具
** execsnoop
execsnoop是一个专为短时进程设计的工具, 通过ftrace实时监控进程的exec行为, 并输出短时进程的基本信息
包括进程PID、父进程PID、命令行参数及执行结果

ftrace是一种常用的动态追踪技术, 一般用于分析Linux内核的运行时行为.


