* 安装
[[https://docs.docker.com/install/linux/docker-ce/ubuntu/][参考文档]]

* 容器
** 介绍
容器其实是一种沙盒技术. 沙盒就是能够像一个集装箱一样将应用装起来的技术, 这样应用于应用之间就有了
边界而不至于互相干扰, 而被装进集装箱的应用, 也可以被方便的搬来搬去, 这就是PaaS最理想的状态.

容器技术的核心功能就是通过约束和修改进程的动态表现, 从而为其创造出一个"边界", 因此容器是一种
特殊的进程.

在容器内, 除了pid=1的进程, 其他进程不受docker控制. 其他进程是指通过exec进去之后启动的后台进程不
受控制, 此处的控制是指它们的回收和生命周期管理.

"敏捷"和"高性能"是容器相较于虚拟机最大的优势.

一个道理: 容器本身没有价值, 有价值的是"容器编排"

** 一些问题
1. 容器是一个单进程, 在一个镜像中集成了jdk, netstat,ping等命令, 该容器启动时是一个java进程,
   但通过docker exec 进入该容器后可以执行ping等命令, 那么这些ping命令在容器的运行过程中是在
   运行的吗?
   答: 这些命令是在运行的, 但不受docker控制, 就像野孩子. 容器的单进程的意思不是只能运行一个进程,
   而是只有一个进程是可控的. 此处的控制指的是它们的回收和生命周期管理.
2. docker容器里跑的进程都是entrypoint进程的子进程. docker基本上是旁路控制的作用.

* 容器基础
[[file:content/docker_base.org][容器基础知识]]

* 使用docker部署一个python测试程序
#+BEGIN_SRC python app.py
from flask import Flask

import socket
import os

app = Flask(__name__)

@app.route("/")
def hello():
    html = "<h3>Hello {name}!</h3>" \
           "<b>Hostname:</b> {hostname} <br/>"
    return html.format(name=os.getenv("NAME", "world"), hostname=socket.gethostname())


if __name__ == "__main__":
    app.run(host="0.0.0.0", port=80)
#+END_SRC
#+BEGIN_SRC text requirements.txt
Flask
#+END_SRC
#+BEGIN_SRC text Dockerfile
from python:2.7-slim
workdir /app
add . /app
run pip install --trusted-host pypi.python.org -r requirements.txt
expose 80
env NAME casper
cmd ["python", "app.py"]
#+END_SRC

docker build -t flask:v1 .  # 构建镜像
docker run -d -p <hostport>:80 flask:v1  # 运行一个容器
docker inspect -f '{{.State.Pid}}'  <containerid>  # 查看容器在宿主机上的进程ID

#+BEGIN_SRC c exec.c  进入某个namespace的c代码
#define _GUN_SOURCE
#include <fcntl.h>
#include <sched.h>
#include <unistd.h>
#include <stdlib.h>
#include <stdio.h>

#define errExit(msg) do {\
    perror(msg);\
    exit(EXIT_FAILURE);\
} while(0)

int main(int argc, char*argv[]) {
    int fd;

    fd = open(argv[1], O_RDONLY);
    if (setns(fd, 0) == -1) {
        errExit("setns");
    }

    execvp(argv[2], &argv[2]);
    errExit("execvp");
}

// 这段代码一共接收两个参数, 第一个参数是当前进程要加入的Namespace文件路径,
// 比如/proc/<PID>ns/net, 第二个参数是需要在该namespace里运行的进程
// 核心操作是: 通过open调用打开了指定的Namespace文件, 将该文件的描述符fd
// 交给setns使用, 在setns执行后, 当前进程就加入了这个文件对应的namespace中了.
#+END_SRC
gcc exec.c -o ESpace

./ESpace /proc/<pid>/ns/net /bin/bash  # 进入指定pid的net namespace中运行/bin/bash命令

docker commit <containerid> xxx:tag  # 将运行的容器提交为一个新的镜像

* 构造容器
[[file:content/buildmydocker.org][构造容器]]

* docker插件开发
** 工作机制
当用户的docker命令中使用了第三方插件, 首先docker客户端会向docker守护进程发起http请求. docker守护
进程发现操作的对象是第三方插件时, 便会从特定的目录文件中发现匹配的插件, 并向其发起HTTP请求.

docker插件是一个单独的进程, 不是docker daemon进程的一个模块. 插件进程与docker daemon进程运行于
同一台机器或者不同的机器上. 通过注册特定的文件到docker daemon的机器上, 使得docker daemon进程
发现插件进程. 插件进程可以运行在容器中, 或者容器外.

docker daemon通过查询插件目录发现插件进程, 目前支持3中格式的文件:
.sock文件: unix domain socket, 该文件的插件必须与docker daemon进程运行在同一台机器上.
.spec: 普通文件, 文件中指定了插件进程的URL, 如: unix:///other.sock或tcp://localhost:8080
.json: 包含了插件的json描述

.spec, .json文件可以运行在另一台机器上, .sock文件必须位于/run/docker/plugins目录下. spec和json
文件必须位于/etc/docker/plugins或者/usr/lib/docker/plugins目录下

文件名就是插件的名称.

docker首先从/run/docker/plugins目录查找.sock文件, 如果找不到再从/etc/docker/plugins目录和
/usr/lib/docker/plugins查找spec和json文件, 如果找到其中一个就停止查找.

插件通常应该在docker daemon启动之前启动, 在docker daemon停止后停止.

docker daemon并不是启动的时候就去激活插件, 而是使用按需加载的方式去激活插件. 因此需要保证
插件进程在用户使用前启动就可以了.

** 利用systemd socket activation功能管理插件
利用systemd的socket activation功能管理插件的启动顺序, docker提供的插件sdk已经支持socket 
activation. 使用该方式需要编写两个文件service文件和socket文件.

* Docker异常总结
** docker ps 无响应, Node节点表现为NotReady
解决方法步骤:
1. 编辑daemon.json文件, 该文件通常位于/etc/docker中, 如果不存在可以创建该文件
2. 添加设置
   #+BEGIN_SRC json
{
    "debug": true
}
   #+END_SRC
3. 向守护进程发送HUP信号以使其重新加载其配置
   sudo kill -SIGHUP $(pidof dockerd)  # pidof是linux系统命令, 用于查找运行程序的进程id
4. 打印堆栈信息
   kill -SIGUSR1 $(pidof dockerd)
   生成的调试信息可以在/var/run/docker/目录中找到
5. 查看dmesg
6. 通过查找社区Issues以及相关PR, 最后发现根本原因是runc的bug.
   使用runc start或runc run启动容器时, (runc [2：INIT])打开一个 fifo 进行写入. 它的父runc进程 
   将打开相同的 fifo 阅读. 通过这种方式, 它们可以同步. 如果stub process 在错误的时间退出,
   那么父 runc 进程会永远被阻塞. 当两个 runc 操作相互竞争时会发生这种情况: runc run / start
   和 runc delete, 它也可能由于其他原因而发生. 例如:内核的OOM killer可以选择杀死 stub process

   解决方案:
   通过解决 exec fifo 竞争来解决这个问题, 如果在我们打开 fifo 之前 stub process 退出,
   那么返回一个错误.

** docker在centos系统下以direct-lvm模式运行, 无法启动
这个问题发生在使用devicemapper存储驱动时Docker试图重用之前使用 LVM thin pool.
例如, 尝试更改节点上的 Docker 的数据目录时会发生此问题. 由于安全措施旨在防止 Docker
因配置问题而意外使用和覆盖 LVM thin pool 中的数据, 因此会发生此错误.

解决方案:
要解决阻止Docker启动的问题, 必须删除并重新创建逻辑卷, 以便Docker将它们视为新的thin pool.
警告: 这些命令将清除Docker数据目录中的所有现有镜像和卷, 在执行这些步骤之前备份所有重要数据.
1. 停止docker
   systemctl stop docker
2. 删除docker目录
   rm -rf /var/lib/docker
3. 删除已经创建的thin pool逻辑卷
   lvremove docker/thinpool
4. 创建新的逻辑卷
   lvcreate -L 500g --thin docker/thinpool --poolmetadatasize 256m
   根据实际磁盘大小调整thinpool和metadata大小

如果需要docker自动配置direct-lvm模式, 可以执行以下步骤:
1. 编辑/etc/docker/daemon.json
   将dm.directlvm_device_force = value从false更改为true.
   #+BEGIN_SRC json
{
    "storage-driver": "devicemapper",
    "storage-opts": [
        "dm.directlvm_device_force=true"
    ]
}
   #+END_SRC
2. 除了删除逻辑卷之外, 还要删除docker卷组
   vgremove docker
3. 启动docker
   systemctl start docker


